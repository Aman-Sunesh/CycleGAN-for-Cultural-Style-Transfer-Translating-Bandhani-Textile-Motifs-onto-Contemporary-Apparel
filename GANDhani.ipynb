{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93175ca9",
   "metadata": {},
   "source": [
    "# GANDhani: CycleGAN for Cultural Style Transfer Translating Bandhani Textile Motifs onto Contemporary Apparel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d746b4",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade7901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid, save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a0b90",
   "metadata": {},
   "source": [
    "### Data Proprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf155d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438822b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6faa883",
   "metadata": {},
   "source": [
    "### Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d99da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, base_features=64):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, base_features, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(base_features, base_features * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(base_features * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(base_features * 2, base_features * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(base_features * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(base_features * 4, base_features * 8, kernel_size=4, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(base_features * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(base_features * 8, 1, kernel_size=4, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a92a0f",
   "metadata": {},
   "source": [
    "### Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cf8a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=0),\n",
    "            nn.InstanceNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=0),\n",
    "            nn.InstanceNorm2d(dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x) # Skip Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba419f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, features=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.g1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(in_channels, features, kernel_size=7, stride=1, padding=0),\n",
    "            nn.InstanceNorm2d(features),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.g2 = nn.Sequential(\n",
    "            nn.Conv2d(features, features*2, kernel_size=3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(features*2),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.g3 = nn.Sequential(\n",
    "            nn.Conv2d(features*2, features*4, kernel_size=3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(features*4),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        res_blocks = []\n",
    "\n",
    "        for _ in range(9):\n",
    "            res_blocks.append(ResidualBlock(features*4))\n",
    "        self.res_blocks = nn.Sequential(*res_blocks)\n",
    "\n",
    "        self.g4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*4, features*2, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(features*2),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.g5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*2, features, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(features),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.g6 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(features, out_channels, kernel_size=7, stride=1, padding=0),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        g1 = self.g1(x)\n",
    "        g2 = self.g2(g1)\n",
    "        g3 = self.g3(g2)\n",
    "        res = self.res_blocks(g3)\n",
    "        g4 = self.g4(res)\n",
    "        g5 = self.g5(g4)\n",
    "        \n",
    "        return self.g6(g5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db5686",
   "metadata": {},
   "source": [
    "### Discriminator Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76cf1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(discriminator_A, discriminator_B,\n",
    "                        generator_A, generator_B,\n",
    "                        real_A, real_B, \n",
    "                        fake_A, fake_B,\n",
    "                        opt_d, criterion_GAN):\n",
    "    \n",
    "    discriminator_A.train()\n",
    "    discriminator_B.train()\n",
    "\n",
    "    # Clear discriminator gradients\n",
    "    opt_d.zero_grad()\n",
    "\n",
    "    # --- Train D_A ---\n",
    "\n",
    "    # ——— Real pairs ———\n",
    "    # D(map, real) should predict “real” → target=1\n",
    "    real_preds_A = discriminator_A(real_A)\n",
    "    real_targets_A = torch.ones_like(real_preds_A)\n",
    "    loss_D_A_real = criterion_GAN(real_preds_A, real_targets_A)\n",
    "    real_score_A = real_preds_A.mean().item()\n",
    "\n",
    "    # ——— Fake pairs ———\n",
    "    # Generate fake images\n",
    "    # G(map) → fake; detach so G’s grad isn’t updated here\n",
    "    fake_preds_A = discriminator_A(fake_A.detach())\n",
    "    fake_targets_A = torch.zeros_like(fake_preds_A)\n",
    "    loss_D_A_fake = criterion_GAN(fake_preds_A, fake_targets_A)\n",
    "    fake_score_A  = fake_preds_A.mean().item()\n",
    "\n",
    "    loss_D_A = 0.5 * (loss_D_A_real + loss_D_A_fake)\n",
    "\n",
    "\n",
    "    # --- Train D_B ---\n",
    "\n",
    "    # ——— Real pairs ———\n",
    "    # D(map, real) should predict “real” → target=1\n",
    "    real_preds_B = discriminator_B(real_B)\n",
    "    real_targets_B = torch.ones_like(real_preds_B)\n",
    "    loss_D_B_real = criterion_GAN(real_preds_B, real_targets_B)\n",
    "    real_score_B = real_preds_B.mean().item()\n",
    "\n",
    "    # ——— Fake pairs ———\n",
    "    # Generate fake images\n",
    "    # G(map) → fake; detach so G’s grad isn’t updated here\n",
    "    fake_preds_B = discriminator_B(fake_B.detach())\n",
    "    fake_targets_B = torch.zeros_like(fake_preds_B)\n",
    "    loss_D_B_fake = criterion_GAN(fake_preds_B, fake_targets_B)\n",
    "    fake_score_B  = fake_preds_B.mean().item()\n",
    "\n",
    "    loss_D_B = 0.5 * (loss_D_B_real + loss_D_B_fake)\n",
    "\n",
    "\n",
    "    # --- Total Discriminator Loss ---\n",
    "    loss_D = loss_D_A + loss_D_B\n",
    "    loss_D.backward()\n",
    "    opt_d.step()\n",
    "    \n",
    "    return {\n",
    "        'loss_D_A': loss_D_A.item(),\n",
    "        'loss_D_B': loss_D_B.item(),\n",
    "        'real_A_score': real_score_A,\n",
    "        'fake_A_score': fake_score_A,\n",
    "        'real_B_score': real_score_B,\n",
    "        'fake_B_score': fake_score_B\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d80fe4",
   "metadata": {},
   "source": [
    "### Generator Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5679633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(discriminator_A, discriminator_B,\n",
    "                        generator_A, generator_B,\n",
    "                        real_A, real_B, \n",
    "                        lambda_a, lambda_b, lambda_id,\n",
    "                        opt_g, criterion_GAN):\n",
    "    \n",
    "    # Clear generator gradients                                     \n",
    "    opt_g.zero_grad()\n",
    "\n",
    "    fake_B = generator_A(real_A)\n",
    "    fake_A = generator_B(real_B)\n",
    "\n",
    "    # --- Train D_A ---\n",
    "\n",
    "    # 1) Adverserial Loss\n",
    "    preds_fake_a = discriminator_A(fake_A)\n",
    "    targets_a = torch.ones_like(preds_fake_a)\n",
    "    adv_total_b = criterion_GAN(preds_fake_a, targets_a)\n",
    "\n",
    "    preds_fake_b = discriminator_B(fake_B)\n",
    "    targets_b = torch.ones_like(preds_fake_b)\n",
    "    adv_total_a = criterion_GAN(preds_fake_b, targets_b)\n",
    "\n",
    "    # 2) Cycle Losses\n",
    "    rec_A = generator_B(fake_B)\n",
    "    rec_B = generator_A(fake_A)\n",
    "\n",
    "    loss_cycle_A = F.l1_loss(rec_A, real_A)\n",
    "    loss_cycle_B = F.l1_loss(rec_B, real_B)\n",
    "\n",
    "    # 3) Identity Loss\n",
    "    idt_B = generator_A(real_B)\n",
    "    idt_A = generator_B(real_A)\n",
    "    identity_a = F.l1_loss(idt_B, real_B)\n",
    "    identity_b = F.l1_loss(idt_A, real_A)\n",
    "\n",
    "    loss_a = adv_total_a + (lambda_a * loss_cycle_A) + (lambda_id * lambda_b * identity_a)\n",
    "    loss_b = adv_total_b + (lambda_b * loss_cycle_B) + (lambda_id * lambda_a * identity_b)\n",
    "\n",
    "    loss_total = loss_a + loss_b\n",
    "    \n",
    "    loss_total.backward()\n",
    "    opt_g.step()\n",
    "\n",
    "    return {\n",
    "        'loss_total': loss_total.item(),\n",
    "        'G_A_loss':   loss_a.item(),\n",
    "        'G_B_loss':   loss_b.item(),\n",
    "        'adv_A':      adv_total_a.item(),\n",
    "        'adv_B':      adv_total_b.item(),\n",
    "        'cycle_A':    loss_cycle_A.item(),\n",
    "        'cycle_B':    loss_cycle_B.item(),\n",
    "        'idt_A':      identity_a.item(),\n",
    "        'idt_B':      identity_b.item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e9b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = 'generated'\n",
    "os.makedirs(sample_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f5c1d",
   "metadata": {},
   "source": [
    "### Saving Generated Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e279c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalize from [-1,1] back to [0,1]\n",
    "def denorm(imgs):\n",
    "    return imgs * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46c117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cycle_samples(\n",
    "    epoch: int,\n",
    "    real_A: torch.Tensor,\n",
    "    real_B: torch.Tensor,\n",
    "    generator_A: nn.Module,\n",
    "    generator_B: nn.Module,\n",
    "    denorm,\n",
    "    sample_dir: str = \"generated\",\n",
    "    nrow: int = 8\n",
    "):\n",
    "    generator_A.eval()\n",
    "    generator_B.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fake_B = generator_A(real_A.to(next(generator_A.parameters()).device))\n",
    "        fake_A = generator_B(real_B.to(next(generator_B.parameters()).device))\n",
    "\n",
    "    # bring back to [0,1]\n",
    "    real_A_vis = denorm(real_A.cpu())\n",
    "    real_B_vis = denorm(real_B.cpu())\n",
    "    fake_A_vis = denorm(fake_A.cpu())\n",
    "    fake_B_vis = denorm(fake_B.cpu())\n",
    "\n",
    "    # make grids\n",
    "    grid_A2B = make_grid(\n",
    "        torch.cat([real_A_vis, fake_B_vis], dim=0),\n",
    "        nrow=nrow,\n",
    "        padding=2,\n",
    "        normalize=False\n",
    "    )\n",
    "    grid_B2A = make_grid(\n",
    "        torch.cat([real_B_vis, fake_A_vis], dim=0),\n",
    "        nrow=nrow,\n",
    "        padding=2,\n",
    "        normalize=False\n",
    "    )\n",
    "\n",
    "    # save\n",
    "    save_image(grid_A2B, os.path.join(sample_dir, f\"A2B_epoch{epoch:03d}.png\"))\n",
    "    save_image(grid_B2A, os.path.join(sample_dir, f\"B2A_epoch{epoch:03d}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ace7dc",
   "metadata": {},
   "source": [
    "### Full Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24add8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size=50):\n",
    "        self.data = []\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def push_and_pop(self, images):\n",
    "        out = []\n",
    "        for img in images:\n",
    "            img = img.unsqueeze(0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(img)\n",
    "                out.append(img)\n",
    "            else:\n",
    "                if random.random() < 0.5:\n",
    "                    i = random.randint(0, self.max_size-1)\n",
    "                    out.append(self.data[i].clone())\n",
    "                    self.data[i] = img\n",
    "                else:\n",
    "                    out.append(img)\n",
    "        return torch.cat(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "163e9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "\n",
    "def lambda_rule(epoch):\n",
    "    # 1.0 for epoch ∈ [0, epochs/2), then linearly to 0 by epoch=epochs\n",
    "    return 1.0 - max(0, epoch - epochs//2) / float(epochs//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2443a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if hasattr(m, \"weight\") and m.weight is not None:\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "            nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        elif isinstance(m, (nn.BatchNorm2d, nn.InstanceNorm2d)):\n",
    "            nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "            \n",
    "    if hasattr(m, \"bias\") and m.bias is not None:\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d07a047",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (3572880838.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef fit()\u001b[39m\n             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m expected ':'\n"
     ]
    }
   ],
   "source": [
    "def fit(\n",
    "    discriminator_A: nn.Module,\n",
    "    discriminator_B: nn.Module,\n",
    "    generator_A:     nn.Module,\n",
    "    generator_B:     nn.Module,\n",
    "    train_dl:        DataLoader,\n",
    "    denorm,\n",
    "    device:          torch.device,\n",
    "    epochs:          int      = 200,\n",
    "    lr:              float    = 2e-4,\n",
    "    lambda_a:        float    = 10.0,\n",
    "    lambda_b:        float    = 10.0,\n",
    "    lambda_id:       float    = 0.5,\n",
    "    pool_size:       int      = 50,\n",
    "    sample_dir:      str      = \"generated\",\n",
    "    nrow:            int      = 8\n",
    "):\n",
    "    opt_G = torch.optim.Adam(\n",
    "        list(generator_A.parameters()) + list(generator_B.parameters()),\n",
    "        lr=lr, betas=(0.5, 0.999)\n",
    "    )\n",
    "    opt_D = torch.optim.Adam(\n",
    "        list(discriminator_A.parameters()) + list(discriminator_B.parameters()),\n",
    "        lr=lr, betas=(0.5, 0.999)\n",
    "    )\n",
    "\n",
    "    sched_G = torch.optim.lr_scheduler.LambdaLR(opt_G, lr_lambda=lambda_rule)\n",
    "    sched_D = torch.optim.lr_scheduler.LambdaLR(opt_D, lr_lambda=lambda_rule)\n",
    "\n",
    "    # grab one fixed batch for visualization \n",
    "    fixed_A, fixed_B = next(iter(train_dl))\n",
    "    fixed_A, fixed_B = fixed_A.to(device), fixed_B.to(device)\n",
    "\n",
    "    criterion_GAN = nn.MSELoss() # LSGAN\n",
    "    buffer_A = ReplayBuffer(pool_size)  # for fake_A\n",
    "    buffer_B = ReplayBuffer(pool_size)  # for fake_B\n",
    "\n",
    "    # ——— history ———\n",
    "    history = {\n",
    "        'G_A': [], 'G_B': [],\n",
    "        'D_A': [], 'D_B': [],\n",
    "        'cycle_A': [], 'cycle_B': [],\n",
    "        'idt_A': [],   'idt_B': [],\n",
    "        'adv_A': [],   'adv_B': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for real_A, real_B in train_dl:\n",
    "            real_A, real_B = real_A.to(device), real_B.to(device)\n",
    "\n",
    "            gen_metrics = train_generator(\n",
    "                discriminator_A, discriminator_B,\n",
    "                generator_A, generator_B,\n",
    "                real_A, real_B,\n",
    "                lambda_a, lambda_b, lambda_id,\n",
    "                opt_G, criterion_GAN\n",
    "            )\n",
    "            \n",
    "            # produce fresh fakes (for the buffer)\n",
    "            fake_B = generator_A(real_A).detach()\n",
    "            fake_A = generator_B(real_B).detach()\n",
    "\n",
    "            # ——— 2) Discriminators ———\n",
    "            # pull from buffer\n",
    "            fake_A_buf = buffer_A.push_and_pop(fake_A)\n",
    "            fake_B_buf = buffer_B.push_and_pop(fake_B)\n",
    "\n",
    "            disc_metrics = train_discriminator(\n",
    "                discriminator_A, discriminator_B,\n",
    "                real_A, real_B,\n",
    "                fake_A_buf, fake_B_buf,\n",
    "                opt_D, criterion_GAN\n",
    "            )\n",
    "\n",
    "            # Log losses & scores\n",
    "            history['G_A'].append(gen_metrics['G_A_loss'])\n",
    "            history['G_B'].append(gen_metrics['G_B_loss'])\n",
    "            history['adv_A'].append(gen_metrics['adv_A'])\n",
    "            history['adv_B'].append(gen_metrics['adv_B'])\n",
    "            history['cycle_A'].append(gen_metrics['cycle_A'])\n",
    "            history['cycle_B'].append(gen_metrics['cycle_B'])\n",
    "            history['idt_A'].append(gen_metrics['idt_A'])\n",
    "            history['idt_B'].append(gen_metrics['idt_B'])\n",
    "\n",
    "            history['D_A'].append(disc_metrics['loss_D_A'])\n",
    "            history['D_B'].append(disc_metrics['loss_D_B'])\n",
    "\n",
    "        # Step the schedulers each epoch\n",
    "        sched_G.step()\n",
    "        sched_D.step()\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            torch.save(generator_A.state_dict(), f\"checkpoint_gen_a_epoch{epoch}.pth\")\n",
    "            torch.save(generator_B.state_dict(), f\"checkpoint_gen_b_epoch{epoch}.pth\")\n",
    "\n",
    "        # every epoch dump sample grids A→B and B→A\n",
    "        save_cycle_samples(\n",
    "            epoch,\n",
    "            fixed_A, fixed_B,\n",
    "            generator_A, generator_B,\n",
    "            denorm,\n",
    "            sample_dir=sample_dir,\n",
    "            nrow=nrow\n",
    "        )\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs}  \"\n",
    "              f\"G_A: {gen_metrics['G_A_loss']:.3f}, \"\n",
    "              f\"G_B: {gen_metrics['G_B_loss']:.3f}, \"\n",
    "              f\"D_A: {disc_metrics['loss_D_A']:.3f}, \"\n",
    "              f\"D_B: {disc_metrics['loss_D_B']:.3f}\")\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66adb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "discriminator_a = Discriminator().to(device)\n",
    "discriminator_b = Discriminator().to(device)\n",
    "generator_a     = Generator().to(device)\n",
    "generator_b     = Generator().to(device)\n",
    "\n",
    "generator_a.apply(init_weights)\n",
    "generator_b.apply(init_weights)\n",
    "discriminator_a.apply(init_weights)\n",
    "discriminator_b.apply(init_weights)\n",
    "\n",
    "history = fit(\n",
    "    discriminator_a=discriminator_a,\n",
    "    discriminator_b=discriminator_b,\n",
    "    generator_a=generator_a,\n",
    "    generator_b=generator_b,\n",
    "    train_dl=train_dl,\n",
    "    denorm=denorm,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdabeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_G_A = history['G_A']\n",
    "losses_G_B = history['G_B']\n",
    "losses_D_A = history['D_A']\n",
    "losses_D_B = history['D_B']\n",
    "adv_A      = history['adv_A']\n",
    "adv_B      = history['adv_B']\n",
    "cycle_A    = history['cycle_A']\n",
    "cycle_B    = history['cycle_B']\n",
    "idt_A      = history['idt_A']\n",
    "idt_B      = history['idt_B']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
